{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketch import MinHashLSH, MinHash, LeanMinHash\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from tqdm import tqdm \n",
    "import os \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMILARITY_THRESHOLD = 0.8\n",
    "NUM_PERMS = 128 \n",
    "SHINGLE_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsh = MinHashLSH(threshold=SIMILARITY_THRESHOLD, num_perm=NUM_PERMS)\n",
    "lsh = MinHashLSH(\n",
    "    threshold=SIMILARITY_THRESHOLD, num_perm=NUM_PERMS, storage_config={\n",
    "        'type': 'cassandra',\n",
    "        'basename': b'base_lsh_cassandra',\n",
    "        'cassandra': {\n",
    "            'seeds': ['127.0.0.1', \"cassandra\"],\n",
    "            'keyspace': 'lsh_test',\n",
    "            'replication': {\n",
    "                'class': 'SimpleStrategy',\n",
    "                'replication_factor': '1',\n",
    "            },\n",
    "            'drop_keyspace': True,\n",
    "            'drop_tables': True,\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9777cb348e954b44a4cbff29be289b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"./temp\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cassandra_lsh(): \n",
    "    lsh = MinHashLSH(\n",
    "        threshold=SIMILARITY_THRESHOLD, num_perm=NUM_PERMS, storage_config={\n",
    "            'type': 'cassandra',\n",
    "            'basename': b'base_lsh_cassandra',\n",
    "            'cassandra': {\n",
    "                'seeds': ['127.0.0.1', \"cassandra\"],\n",
    "                'keyspace': 'lsh_test',\n",
    "                'replication': {\n",
    "                    'class': 'SimpleStrategy',\n",
    "                    'replication_factor': '1',\n",
    "                },\n",
    "                'drop_keyspace': False,\n",
    "                'drop_tables': False,\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return lsh\n",
    "\n",
    "def _shingle(string, shingle_size=SHINGLE_SIZE):\n",
    "    shings = {\n",
    "        string[i : i + shingle_size].encode(\"utf8\")\n",
    "        for i in range(len(string) - shingle_size + 1)\n",
    "    }\n",
    "    return set(shings)\n",
    "\n",
    "def hash_and_insert(batch, indices, session): \n",
    "    for i, row in enumerate(batch[\"text\"]):  \n",
    "        shingles = _shingle(row, shingle_size=SHINGLE_SIZE)\n",
    "        # shingles = [shing.encode(\"utf8\") for shing in shingles]\n",
    "\n",
    "        if len(shingles) != 0: \n",
    "            minhash = MinHash(num_perm=NUM_PERMS)\n",
    "            for shing in shingles: \n",
    "                minhash.update(shing)\n",
    "\n",
    "            minhash = LeanMinHash(minhash=minhash)\n",
    "            session.insert(str(indices[i]), minhash, check_duplication=False)\n",
    "\n",
    "    return batch\n",
    "\n",
    "def hash_and_insert_with_basename(batch, indices): \n",
    "    lsh = get_cassandra_lsh()\n",
    "\n",
    "    with lsh.insertion_session() as session: \n",
    "        for i, row in enumerate(batch[\"text\"]):  \n",
    "            shingles = _shingle(row, shingle_size=SHINGLE_SIZE)\n",
    "            # shingles = [shing.encode(\"utf8\") for shing in shingles]\n",
    "\n",
    "            if len(shingles) != 0: \n",
    "                minhash = MinHash(num_perm=NUM_PERMS)\n",
    "                for shing in shingles: \n",
    "                    minhash.update(shing)\n",
    "\n",
    "                minhash = LeanMinHash(minhash=minhash)\n",
    "                session.insert(str(indices[i]), minhash, check_duplication=False)\n",
    "\n",
    "    return batch\n",
    "\n",
    "def hash_insert_mark_with_basename(batch, indices): \n",
    "    lsh = get_cassandra_lsh()\n",
    "\n",
    "    for i, row in enumerate(batch[\"text\"]):  \n",
    "        shingles = _shingle(row, shingle_size=SHINGLE_SIZE)\n",
    "        # shingles = [shing.encode(\"utf8\") for shing in shingles]\n",
    "\n",
    "        if len(shingles) != 0: \n",
    "            minhash = MinHash(num_perm=NUM_PERMS)\n",
    "            for shing in shingles: \n",
    "                minhash.update(shing)\n",
    "\n",
    "            minhash = LeanMinHash(minhash=minhash)\n",
    "            query = lsh.query(minhash)\n",
    "            \n",
    "            if len(query) == 0: \n",
    "                lsh.insert(str(indices[i]), minhash, check_duplication=False)\n",
    "                batch[\"is_duplicate\"][i] = False\n",
    "            else: \n",
    "                batch[\"is_duplicate\"][i] = True\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal iterative solution \n",
    "with lsh.insertion_session() as session: \n",
    "    for i, sample in tqdm(enumerate(dataset)): \n",
    "        shingles = _shingle(sample[\"text\"], shingle_size=SHINGLE_SIZE)\n",
    "        # shingles = [shing.encode(\"utf8\") for shing in shingles]\n",
    "\n",
    "        if len(shingles) != 0: \n",
    "            minhash = MinHash(num_perm=NUM_PERMS)\n",
    "            for shing in shingles: \n",
    "                minhash.update(shing)\n",
    "\n",
    "            minhash = LeanMinHash(minhash=minhash)\n",
    "            session.insert(str(i), minhash, check_duplication=False)\n",
    "\n",
    "\n",
    "    with open(\"./lsh.pkl\", \"wb\") as f:\n",
    "        pickle.dump(lsh, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d2973847784eefa5f1fc8fe734992c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/214424 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# parallel solution with multiple lsh \n",
    "dataset = dataset.map(hash_and_insert_with_basename, batched=True, batch_size=10000, num_proc=os.cpu_count(), with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel solution with 1 LSH \n",
    "with lsh.insertion_session() as session: \n",
    "    dataset = dataset.map(hash_and_insert, batched=True, batch_size=2000, num_proc=os.cpu_count(), with_indices=True, fn_kwargs={\"session\": session})\n",
    "\n",
    "    with open(\"./lsh.pkl\", \"wb\") as f:\n",
    "        pickle.dump(lsh, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh = get_cassandra_lsh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf999b48797b4e6f9ebffb9e1ae36446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/214424 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_is_duplicate_column(example):\n",
    "    example[\"is_duplicate\"] = True  # Initialize to False\n",
    "    return example\n",
    "\n",
    "# Apply the function to the entire dataset\n",
    "dataset = dataset.map(add_is_duplicate_column, num_proc=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marked_duplicate(batch, indices):\n",
    "    lsh = get_cassandra_lsh()\n",
    "    for i, row in enumerate(batch[\"text\"]):\n",
    "        try:\n",
    "            lsh.__contains__(str(indices[i]))\n",
    "            shingles = _shingle(row, shingle_size=SHINGLE_SIZE)\n",
    "\n",
    "            if len(shingles) != 0:\n",
    "                minhash = MinHash(num_perm=NUM_PERMS)\n",
    "                for shing in shingles:\n",
    "                    minhash.update(shing)\n",
    "\n",
    "                    query = lsh.query(minhash=minhash)\n",
    "\n",
    "                    if len(query) == 0:\n",
    "                        batch[\"is_duplicate\"][i] = False\n",
    "                    else:\n",
    "                        for id in query:\n",
    "                            if id == indices[i]:\n",
    "                                batch[\"is_duplicate\"][i] = False\n",
    "                            else:\n",
    "                                lsh.remove(id)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = dataset[0][\"text\"]\n",
    "\n",
    "minhash = MinHash(num_perm=NUM_PERMS)\n",
    "shingles = _shingle(test_text)\n",
    "\n",
    "for shing in shingles: \n",
    "    minhash.update(shing) \n",
    "\n",
    "lean = LeanMinHash(minhash=minhash)\n",
    "lsh.insert(\"0\", lean, check_duplication=False)\n",
    "\n",
    "lsh.__contains__(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580f9ecd51b34b3087cf043a68948d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/214424 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(marked_duplicate, batched=True, with_indices=True, batch_size=10000, num_proc=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in tqdm(enumerate(dataset), total=len(dataset)): \n",
    "    if sample[\"is_duplicate\"] == False: \n",
    "        shingles = _shingle(sample[\"text\"], shingle_size=SHINGLE_SIZE)\n",
    "\n",
    "        if len(shingles) != 0: \n",
    "            minhash = MinHash(num_perm=NUM_PERMS)\n",
    "            for shing in shingles: \n",
    "                minhash.update(shing)\n",
    "\n",
    "            lean = LeanMinHash(minhash=minhash)\n",
    "\n",
    "            query = lsh.query(lean) \n",
    "\n",
    "            for id in query: \n",
    "                id = int(id) \n",
    "                if id != i: \n",
    "                    dataset[id][\"is_duplicate\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.filter(lambda x: x[\"is_duplicate\"] == False, num_proc=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save_to_disk(\"deduplicated_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"deduplicated_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./lsh.pkl\", \"rb\") as f:\n",
    "    session = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = dataset[1][\"text\"]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "shingles = _shingle(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "minhash = MinHash(num_perm=NUM_PERMS)\n",
    "\n",
    "for shing in shingles: \n",
    "    minhash.update(shing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.query(minhash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.is_empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketch import MinHash, MinHashLSH\n",
    "import numpy as np\n",
    "\n",
    "minhashes = []\n",
    "for i in range(100):\n",
    "    m = MinHash(num_perm=128)\n",
    "    m.update_batch(np.random.randint(low=0, high=30, size=10))\n",
    "    minhashes.append(m)\n",
    "\n",
    "session = MinHashLSH(threshold=0.5, num_perm=128)\n",
    "with session.insertion_session() as session:\n",
    "    for i, m in enumerate(minhashes):\n",
    "        session.insert(i, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.is_empty()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
